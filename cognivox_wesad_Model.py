# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f89TgvrjtUjNxAO5RkXOL-yf_nEyXcQD
"""

from google.colab import drive
drive.mount('/content/drive')   # Accept the prompt

# Path to your WESAD folder in Drive (based on your screenshot)
DATA_ROOT = "/content/drive/MyDrive/WESAD"

import os
import pickle
import numpy as np
import pandas as pd
from scipy.signal import resample
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

subjects = sorted([d for d in os.listdir(DATA_ROOT) if d.startswith("S")])
print("Subjects:", subjects)

def load_subject(subject_id):
    """
    subject_id: e.g. 'S2', 'S3'
    returns: dict loaded from Sx.pkl
    """
    pkl_path = os.path.join(DATA_ROOT, subject_id, f"{subject_id}.pkl")
    with open(pkl_path, "rb") as f:
        data = pickle.load(f, encoding="latin1")
    return data

# Test on one subject
sub_id = "S2"
data_s2 = load_subject(sub_id)

print("Top-level keys:", data_s2.keys())
print("Signal keys:", data_s2["signal"].keys())
print("Wrist channels:", data_s2["signal"]["wrist"].keys())
print("Label shape:", np.array(data_s2["label"]).shape)
print("Unique labels:", np.unique(data_s2["label"]))

# Sampling rate of wrist data in WESAD (from README): 32 Hz
FS_WRIST = 32

# Window settings (10s window, 5s step)
WINDOW_SEC = 10
STEP_SEC = 5
WINDOW = WINDOW_SEC * FS_WRIST
STEP = STEP_SEC * FS_WRIST

def map_label_multiclass_to_binary(lbl):
    """
    Map original WESAD labels to binary.

    Original (typical):
      0 = undefined / transition
      1 = baseline
      2 = stress (TSST)
      3 = amusement
      4 = meditation

    We'll treat only label 2 as 'stress' (1) and 1/3/4 as 'non-stress' (0).
    0 and anything else => ignore.
    """
    if lbl == 2:
        return 1
    elif lbl in [1, 3, 4]:
        return 0
    else:
        return -1  # ignore

def get_wrist_signals_and_labels(sub_data):
    wrist = sub_data["signal"]["wrist"]
    eda = np.array(wrist["EDA"])
    bvp = np.array(wrist["BVP"])
    acc = np.array(wrist["ACC"])  # shape (N,3)
    temp = np.array(wrist["TEMP"])
    labels_full = np.array(sub_data["label"])

    # Resample labels to match wrist length
    labels_resampled = resample(labels_full, len(eda))
    labels_resampled = np.rint(labels_resampled).astype(int)

    return eda, bvp, acc, temp, labels_resampled

def extract_window_features(eda_w, bvp_w, acc_w, temp_w):
    """
    eda_w, bvp_w, temp_w: 1D arrays (window)
    acc_w: 2D array (window, 3)
    returns: dict of features
    """
    feats = {}

    # EDA
    feats["eda_mean"] = float(np.mean(eda_w))
    feats["eda_std"] = float(np.std(eda_w))
    feats["eda_min"] = float(np.min(eda_w))
    feats["eda_max"] = float(np.max(eda_w))

    # BVP
    feats["bvp_mean"] = float(np.mean(bvp_w))
    feats["bvp_std"] = float(np.std(bvp_w))

    # TEMP
    feats["temp_mean"] = float(np.mean(temp_w))
    feats["temp_std"] = float(np.std(temp_w))

    # ACC magnitude
    mag = np.linalg.norm(acc_w, axis=1)  # sqrt(x^2 + y^2 + z^2)
    feats["acc_mag_mean"] = float(np.mean(mag))
    feats["acc_mag_std"] = float(np.std(mag))

    return feats

def build_subject_windows(subject_id):
    """
    Build a list of {features..., label, subject} for one subject.
    """
    sub_data = load_subject(subject_id)
    eda, bvp, acc, temp, labels = get_wrist_signals_and_labels(sub_data)

    n = len(eda)
    rows = []

    for start in range(0, n - WINDOW, STEP):
        end = start + WINDOW

        lab_window = labels[start:end]
        # majority label in this window
        vals, counts = np.unique(lab_window, return_counts=True)
        maj_label = vals[np.argmax(counts)]
        bin_label = map_label_multiclass_to_binary(maj_label)

        # skip windows with undefined labels
        if bin_label == -1:
            continue

        feats = extract_window_features(
            eda[start:end],
            bvp[start:end],
            acc[start:end],
            temp[start:end],
        )
        feats["label"] = bin_label
        feats["subject"] = subject_id
        rows.append(feats)

    return rows

rows_s2 = build_subject_windows("S2")
print("Number of windows from S2:", len(rows_s2))
print("First row keys:", rows_s2[0].keys())
print("Label distribution in S2:", pd.Series([r["label"] for r in rows_s2]).value_counts())

all_rows = []
for sid in subjects:
    print("Processing", sid)
    try:
        rows = build_subject_windows(sid)
        all_rows.extend(rows)
    except Exception as e:
        print("  Error with", sid, ":", e)

df = pd.DataFrame(all_rows)
print("Dataset shape:", df.shape)
print(df["label"].value_counts())
df.head()

feature_cols = [c for c in df.columns if c not in ["label", "subject"]]

X = df[feature_cols].values
y = df["label"].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

clf = RandomForestClassifier(
    n_estimators=200,
    random_state=42,
    class_weight="balanced"
)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print(classification_report(y_test, y_pred))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

import joblib

MODEL_PATH = "/content/drive/MyDrive/cognivox_wesad_rf.joblib"

joblib.dump(
    {
        "model": clf,
        "feature_cols": feature_cols,
        "window_sec": WINDOW_SEC,
        "step_sec": STEP_SEC,
        "fs_wrist": FS_WRIST,
    },
    MODEL_PATH,
)

print("Saved model to:", MODEL_PATH)

import joblib
obj = joblib.load(MODEL_PATH)
rf = obj["model"]
feat_cols = obj["feature_cols"]

# Take one random row from df
sample_row = df.sample(1, random_state=0)
sample_X = sample_row[feat_cols].values
true_label = int(sample_row["label"].iloc[0])

pred_label = int(rf.predict(sample_X)[0])
print("True label:", true_label, "Predicted:", pred_label)

import joblib
import numpy as np

# Load model we saved earlier (if not already in memory)
MODEL_PATH = "/content/drive/MyDrive/cognivox_wesad_rf.joblib"
obj = joblib.load(MODEL_PATH)

model = obj["model"]
feature_cols = obj["feature_cols"]

def predict_stress_from_features(feat_dict, threshold=0.6):
    """
    feat_dict: dict of features, e.g. {
        'eda_mean': ..., 'eda_std': ..., ... 'acc_mag_std': ...
    }
    threshold: probability threshold to classify as stress
    returns: label (0/1), stress_score (0-1)
    """
    x = np.array([[feat_dict[col] for col in feature_cols]])
    proba = model.predict_proba(x)[0, 1]  # probability of class 1 (stress)
    label = 1 if proba >= threshold else 0
    return label, float(proba)


def generate_suggestion(label, stress_score):
    """
    Map prediction -> human-friendly suggestion.
    """
    if label == 0:
        # non-stress
        if stress_score < 0.3:
            return "You are calm. Keep going ðŸ‘"
        else:
            return "Slight stress detected. Maintain your pace and breathing."
    else:
        # stress
        if stress_score < 0.75:
            return "You seem stressed. Try slowing your speech and taking a deep breath."
        else:
            return "High stress detected. Pause for a moment, breathe slowly, then continue."

# ---- Test on a random window from your dataset ----
sample_row = df.sample(1, random_state=1)
feat_dict = sample_row[feature_cols].iloc[0].to_dict()
true_label = int(sample_row["label"].iloc[0])

pred_label, score = predict_stress_from_features(feat_dict)
suggestion = generate_suggestion(pred_label, score)

print("True label       :", true_label)
print("Predicted label  :", pred_label)
print("Stress score     :", round(score, 3))
print("Suggestion       :", suggestion)

# Choose a subject to simulate live streaming
sim_subject_id = "S2"
sub_data = load_subject(sim_subject_id)
eda, bvp, acc, temp, labels = get_wrist_signals_and_labels(sub_data)

n = len(eda)

print("Simulating real-time windows...")
for start in range(0, n - WINDOW, STEP):
    end = start + WINDOW

    # Extract features for this "live" window
    feats = extract_window_features(
        eda[start:end],
        bvp[start:end],
        acc[start:end],
        temp[start:end],
    )

    # Predict stress and suggestion
    label, score = predict_stress_from_features(feats)
    suggestion = generate_suggestion(label, score)

    # For demo: get majority true label for reference
    lab_window = labels[start:end]
    vals, counts = np.unique(lab_window, return_counts=True)
    true_lab_multi = vals[np.argmax(counts)]
    true_lab_bin = map_label_multiclass_to_binary(true_lab_multi)

    print(f"Window {start:6d}-{end:6d} | True={true_lab_bin} Pred={label} Score={score:.2f} | {suggestion}")