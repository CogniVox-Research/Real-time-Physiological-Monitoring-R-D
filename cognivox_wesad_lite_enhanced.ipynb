{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1gRn5yAnxUf",
        "outputId": "e81ab847-bb8e-4569-c551-3e53382f189e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Subjects: ['S10', 'S11', 'S13', 'S14', 'S15', 'S16', 'S17', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.signal import resample\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# Path to your WESAD folder\n",
        "DATA_ROOT = \"/content/drive/MyDrive/WESAD\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/cognivox_wesad_lite.joblib\" # Note the new filename\n",
        "\n",
        "# Sampling rate of wrist data (We use ACC as reference which is 32Hz)\n",
        "FS_WRIST = 32\n",
        "\n",
        "# Window settings (10s window, 5s step)\n",
        "WINDOW_SEC = 10\n",
        "STEP_SEC = 5\n",
        "WINDOW = WINDOW_SEC * FS_WRIST\n",
        "STEP = STEP_SEC * FS_WRIST\n",
        "\n",
        "subjects = sorted([d for d in os.listdir(DATA_ROOT) if d.startswith(\"S\")])\n",
        "print(\"Subjects:\", subjects)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_subject(subject_id):\n",
        "    pkl_path = os.path.join(DATA_ROOT, subject_id, f\"{subject_id}.pkl\")\n",
        "    with open(pkl_path, \"rb\") as f:\n",
        "        data = pickle.load(f, encoding=\"latin1\")\n",
        "    return data\n",
        "\n",
        "def map_label_multiclass_to_binary(lbl):\n",
        "    # 2 = Stress, [1, 3, 4] = Non-Stress, Others = Ignore\n",
        "    if lbl == 2:\n",
        "        return 1\n",
        "    elif lbl in [1, 3, 4]:\n",
        "        return 0\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "def get_wrist_signals_and_labels(sub_data):\n",
        "    wrist = sub_data[\"signal\"][\"wrist\"]\n",
        "\n",
        "    # 1. Load Accelerometer (Reference: 32Hz)\n",
        "    acc = np.array(wrist[\"ACC\"])\n",
        "\n",
        "    # 2. Load BVP (Originally 64Hz) and Resample to 32Hz to match ACC\n",
        "    bvp_original = np.array(wrist[\"BVP\"]).flatten()\n",
        "    bvp = resample(bvp_original, len(acc))\n",
        "\n",
        "    # 3. Load Labels and Resample to match ACC\n",
        "    labels_full = np.array(sub_data[\"label\"])\n",
        "    labels_resampled = resample(labels_full, len(acc))\n",
        "    labels_resampled = np.rint(labels_resampled).astype(int)\n",
        "\n",
        "    # Note: We completely ignore EDA and TEMP here\n",
        "    return bvp, acc, labels_resampled"
      ],
      "metadata": {
        "id": "f3ghRMOCojA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract_window_features(bvp_w, acc_w):\n",
        "#     \"\"\"\n",
        "#     bvp_w: 1D array (window)\n",
        "#     acc_w: 2D array (window, 3)\n",
        "#     returns: dict of features\n",
        "#     \"\"\"\n",
        "#     feats = {}\n",
        "\n",
        "#     # --- BVP (Heart Rate Proxy) ---\n",
        "#     feats[\"bvp_mean\"] = float(np.mean(bvp_w))\n",
        "#     feats[\"bvp_std\"] = float(np.std(bvp_w))\n",
        "\n",
        "#     # --- ACC (Motion) ---\n",
        "#     # Calculate magnitude: sqrt(x^2 + y^2 + z^2)\n",
        "#     mag = np.linalg.norm(acc_w, axis=1)\n",
        "#     feats[\"acc_mag_mean\"] = float(np.mean(mag))\n",
        "#     feats[\"acc_mag_std\"] = float(np.std(mag))\n",
        "\n",
        "#     return feats\n",
        "def extract_window_features(bvp_w, acc_w):\n",
        "    feats = {}\n",
        "\n",
        "    # --- ENHANCED BVP (Heart Rate) FEATURES ---\n",
        "    # simple statistics\n",
        "    feats[\"bvp_mean\"] = float(np.mean(bvp_w))\n",
        "    feats[\"bvp_std\"] = float(np.std(bvp_w))\n",
        "    feats[\"bvp_min\"] = float(np.min(bvp_w))\n",
        "    feats[\"bvp_max\"] = float(np.max(bvp_w))\n",
        "\n",
        "    # Range (Max - Min) helps detect spikes\n",
        "    feats[\"bvp_range\"] = feats[\"bvp_max\"] - feats[\"bvp_min\"]\n",
        "\n",
        "    # Energy (Sum of squares) can indicate intensity\n",
        "    feats[\"bvp_energy\"] = float(np.sum(bvp_w**2)) / len(bvp_w)\n",
        "\n",
        "    # --- ACC (Motion) ---\n",
        "    mag = np.linalg.norm(acc_w, axis=1)\n",
        "    feats[\"acc_mean\"] = float(np.mean(mag))\n",
        "    feats[\"acc_std\"] = float(np.std(mag))\n",
        "    feats[\"acc_max\"] = float(np.max(mag)) # Max movement intensity\n",
        "\n",
        "    return feats\n",
        "\n",
        "def build_subject_windows(subject_id):\n",
        "    sub_data = load_subject(subject_id)\n",
        "    # Get only BVP and ACC\n",
        "    bvp, acc, labels = get_wrist_signals_and_labels(sub_data)\n",
        "\n",
        "    n = len(acc)\n",
        "    rows = []\n",
        "\n",
        "    for start in range(0, n - WINDOW, STEP):\n",
        "        end = start + WINDOW\n",
        "\n",
        "        lab_window = labels[start:end]\n",
        "\n",
        "        # Check label majority\n",
        "        vals, counts = np.unique(lab_window, return_counts=True)\n",
        "        if len(vals) == 0: continue\n",
        "        maj_label = vals[np.argmax(counts)]\n",
        "        bin_label = map_label_multiclass_to_binary(maj_label)\n",
        "\n",
        "        if bin_label == -1:\n",
        "            continue\n",
        "\n",
        "        # Extract features (No EDA/Temp passed)\n",
        "        feats = extract_window_features(\n",
        "            bvp[start:end],\n",
        "            acc[start:end]\n",
        "        )\n",
        "        feats[\"label\"] = bin_label\n",
        "        feats[\"subject\"] = subject_id\n",
        "        rows.append(feats)\n",
        "\n",
        "    return rows"
      ],
      "metadata": {
        "id": "D53ACSMYoprC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Re-build Dataset with New Features\n",
        "print(\"Re-building dataset with enhanced features...\")\n",
        "all_rows = []\n",
        "for sid in subjects:\n",
        "    try:\n",
        "        # Re-using the build logic but it will call the NEW extract_window_features above\n",
        "        rows = build_subject_windows(sid)\n",
        "        all_rows.extend(rows)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with {sid}: {e}\")\n",
        "\n",
        "df_lite = pd.DataFrame(all_rows)\n",
        "print(\"New Dataset Shape:\", df_lite.shape)\n",
        "\n",
        "# 3. Train Model\n",
        "feature_cols = [c for c in df_lite.columns if c not in [\"label\", \"subject\"]]\n",
        "X = df_lite[feature_cols].values\n",
        "y = df_lite[\"label\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Increased estimators to 300 to capture the extra detail\n",
        "clf_lite = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced\",  # Critical for fixing the low Recall\n",
        "    n_jobs=-1\n",
        ")\n",
        "clf_lite.fit(X_train, y_train)\n",
        "\n",
        "# 4. Show New Results\n",
        "print(\"\\n--- NEW ACCURACY RESULTS (Lite Model) ---\")\n",
        "y_pred = clf_lite.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# 5. Save if results are good\n",
        "MODEL_PATH = \"/content/drive/MyDrive/cognivox_wesad_lite_enhanced.joblib\"\n",
        "joblib.dump(\n",
        "    {\n",
        "        \"model\": clf_lite,\n",
        "        \"feature_cols\": feature_cols,\n",
        "        \"window_sec\": WINDOW_SEC,\n",
        "        \"step_sec\": STEP_SEC,\n",
        "        \"fs_wrist\": FS_WRIST,\n",
        "    },\n",
        "    MODEL_PATH,\n",
        ")\n",
        "print(f\"Enhanced model saved to: {MODEL_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk8tGqRYowOS",
        "outputId": "f1c87027-8abb-496b-d83f-86440c3b78a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-building dataset with enhanced features...\n",
            "New Dataset Shape: (8991, 11)\n",
            "\n",
            "--- NEW ACCURACY RESULTS (Lite Model) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93      1400\n",
            "           1       0.83      0.65      0.73       399\n",
            "\n",
            "    accuracy                           0.89      1799\n",
            "   macro avg       0.87      0.80      0.83      1799\n",
            "weighted avg       0.89      0.89      0.89      1799\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1348   52]\n",
            " [ 141  258]]\n",
            "Enhanced model saved to: /content/drive/MyDrive/cognivox_wesad_lite_enhanced.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KGpXYXqPqB9K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}